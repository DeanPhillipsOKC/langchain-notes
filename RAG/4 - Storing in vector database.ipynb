{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e86918c-ee42-4b17-a4fb-360010268849",
   "metadata": {},
   "source": [
    "#### Get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2996f412-b297-4d4c-8345-83136ea56e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b2cbd73-41b2-4163-b978-17ec6203b1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./files/LangchainRetrieval.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0242437-24d3-4267-95fb-eeab0563c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b7d41c-45a6-4417-b928-509400eba667",
   "metadata": {},
   "source": [
    "#### Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7ec3363-c220-40c9-88b5-b428deca8a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d38cd4d2-a600-4696-8f55-10bf2a9f62c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d4ac021-29b3-48b6-9ba2-02340afe64d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = splitter.split_documents(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eecadb-ed6c-493e-be13-6f86921a3a30",
   "metadata": {},
   "source": [
    "#### Embed and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24bd1328-54dd-45dd-b190-e057e4eaa5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85df31ea-f252-4656-a455-8e3fb1edb620",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_function = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "781dfd17-265f-45fc-bdeb-9bb7b4811c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.chroma import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf83cdb6-7f5f-4f92-b7af-1bdc92a13f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = Chroma.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb181c-d368-4052-8b43-3ab138262992",
   "metadata": {},
   "source": [
    "#### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ffbfa0-bd01-4a2a-ad7f-b0e60488d42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is text embedding and how does langchain help in doing it?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c191d056-0194-4024-8c29-40e534dc5fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "queried_docs = db.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fdcd43b-8f5a-4781-a11b-3e2f258f8cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embedding models\n",
      "Another key part of retrieval is creating embeddings for documents. Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of a text that are similar. LangChain provides integrations with over 25 different embedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs. LangChain provides a standard interface, allowing you to easily swap between models.\n",
      "\n",
      "Vector stores\n",
      "With the rise of embeddings, there has emerged a need for databases to support efficient storage and searching of these embeddings. LangChain provides integrations with over 50 different vectorstores, from open-source local ones to cloud-hosted proprietary ones, allowing you to choose the one best suited for your needs. LangChain exposes a standard interface, allowing you to easily swap between vector stores.\n"
     ]
    }
   ],
   "source": [
    "print(queried_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94afc346-9a40-4008-a8c6-5c11e0c654fc",
   "metadata": {},
   "source": [
    "#### Retrievers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49cf4d4c-2ec6-40df-a38a-f6fd37012125",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "961cffea-82ca-4329-b6e6-fb5d2dd619db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c73e860-8ffe-4110-98b0-78441680d5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the following question based only on the following context.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "{context}\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ee35120-f527-486e-8425-04add7e7ab42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe31532a-32a2-4d04-8df9-ae7d65eb12c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "381bdabc-2185-4c2b-b788-0fcbf00a71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "061eb794-d35e-4ee4-8bc3-82669cb3403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df34fe93-d263-47e2-8998-ff471c054502",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f813a93-e35c-4a08-83c3-f6b7a4ae1e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text embedding is the process of creating embeddings for documents, which capture the semantic meaning of the text and allow for efficient retrieval of similar pieces of text. LangChain helps in text embedding by providing integrations with various embedding providers and methods, allowing users to choose the best option for their needs. It also offers a standard interface for easy swapping between different models.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is text embedding and how does langchain help in doing it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4edc3b0-bb91-49ab-bef4-22c5ca11da26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
